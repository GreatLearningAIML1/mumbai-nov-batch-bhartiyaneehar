{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84Q8JfvaeZZ6"
   },
   "source": [
    "## Linear Classifier in TensorFlow \n",
    "Using Low Level API in Eager Execution mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neeha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mjtb-EMcm5K0"
   },
   "outputs": [],
   "source": [
    "#Enable Eager Execution if using tensflow version < 2.0\n",
    "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiObW4V4SIOz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data_prices = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open       close         low        high  \\\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
       "\n",
       "      volume  \n",
       "0  2163600.0  \n",
       "1  2386400.0  \n",
       "2  2489500.0  \n",
       "3  2006300.0  \n",
       "4  1408600.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>8.512640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.836986</td>\n",
       "      <td>70.857109</td>\n",
       "      <td>70.118414</td>\n",
       "      <td>71.543476</td>\n",
       "      <td>5.415113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.695876</td>\n",
       "      <td>83.689686</td>\n",
       "      <td>82.877294</td>\n",
       "      <td>84.465504</td>\n",
       "      <td>1.249468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.840000</td>\n",
       "      <td>33.849998</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>34.189999</td>\n",
       "      <td>1.221500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.770000</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>52.230000</td>\n",
       "      <td>53.310001</td>\n",
       "      <td>2.476250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.879997</td>\n",
       "      <td>79.889999</td>\n",
       "      <td>79.110001</td>\n",
       "      <td>80.610001</td>\n",
       "      <td>5.222500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1584.439941</td>\n",
       "      <td>1578.130005</td>\n",
       "      <td>1549.939941</td>\n",
       "      <td>1600.930054</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open          close            low           high  \\\n",
       "count  851264.000000  851264.000000  851264.000000  851264.000000   \n",
       "mean       70.836986      70.857109      70.118414      71.543476   \n",
       "std        83.695876      83.689686      82.877294      84.465504   \n",
       "min         0.850000       0.860000       0.830000       0.880000   \n",
       "25%        33.840000      33.849998      33.480000      34.189999   \n",
       "50%        52.770000      52.799999      52.230000      53.310001   \n",
       "75%        79.879997      79.889999      79.110001      80.610001   \n",
       "max      1584.439941    1578.130005    1549.939941    1600.930054   \n",
       "\n",
       "             volume  \n",
       "count  8.512640e+05  \n",
       "mean   5.415113e+06  \n",
       "std    1.249468e+07  \n",
       "min    0.000000e+00  \n",
       "25%    1.221500e+06  \n",
       "50%    2.476250e+06  \n",
       "75%    5.222500e+06  \n",
       "max    8.596434e+08  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prices.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data_prices=data_prices[[ 'open', 'close', 'low', 'high', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
    "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "data_prices['volume']=data_prices['volume']/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prices=data_prices.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LE4U8lTdQJq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_prices['volume']\n",
    "X=data_prices[[ 'open', 'close', 'low', 'high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr=np.array(X).astype(np.float32)\n",
    "y_arr=np.array(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYK-aUuLbrz2"
   },
   "source": [
    "#### Convert Training and Test Data to numpy float32 arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ao-S0tQGcncz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_arr=np.array(X_train).astype(np.float32)\n",
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test_arr=np.array(X_test).astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "im1ZegbDdKgv"
   },
   "source": [
    "### Normalize the data\n",
    "You can use Normalizer from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "nm=Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=nm.fit_transform(X_train)\n",
    "X_test=nm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the Model in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L205qPeQOB7B"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros(shape=[4,1]), name=\"Weights\")\n",
    "b = tf.Variable(tf.zeros(shape=[1]),name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define a function to calculate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "def predict_model(X_train,W,b):#X_train\n",
    "    return tf.add(tf.matmul(X_train,W),b,name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "def loss_func(y,y_pred):#y_train, y_ for prediction\n",
    "    return tf.reduce_mean(tf.square(y-y_pred),name='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, W, b):#X_train & y_train\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch([W,b])\n",
    "        y_pred=predict_model(X,W,b)\n",
    "        loss=loss_func(y,y_pred) \n",
    "    DW,Db =t.gradient(loss,[W,b])\n",
    "    W=W-DW*0.03\n",
    "    b=b-Db*0.03\n",
    "    return W,b,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Function to train the Model\n",
    "\n",
    "1.   Record all the mathematical steps to calculate Loss\n",
    "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
    "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "W,b,l = train(X_train, y_train, W, b) #Training by passing X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12060, shape=(), dtype=float32, numpy=229.31682>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the model for 100 epochs \n",
    "1. Observe the training loss at every iteration\n",
    "2. Observe Test loss at every 5th iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(223.2096, shape=(), dtype=float32)\n",
      "1 tf.Tensor(218.48, shape=(), dtype=float32)\n",
      "2 tf.Tensor(214.81747, shape=(), dtype=float32)\n",
      "3 tf.Tensor(211.9812, shape=(), dtype=float32)\n",
      "4 tf.Tensor(209.78473, shape=(), dtype=float32)\n",
      "5 tf.Tensor(208.0838, shape=(), dtype=float32)\n",
      "6 tf.Tensor(206.76657, shape=(), dtype=float32)\n",
      "7 tf.Tensor(205.74644, shape=(), dtype=float32)\n",
      "8 tf.Tensor(204.9565, shape=(), dtype=float32)\n",
      "9 tf.Tensor(204.34483, shape=(), dtype=float32)\n",
      "10 tf.Tensor(203.87103, shape=(), dtype=float32)\n",
      "11 tf.Tensor(203.50421, shape=(), dtype=float32)\n",
      "12 tf.Tensor(203.22014, shape=(), dtype=float32)\n",
      "13 tf.Tensor(203.00009, shape=(), dtype=float32)\n",
      "14 tf.Tensor(202.82977, shape=(), dtype=float32)\n",
      "15 tf.Tensor(202.6978, shape=(), dtype=float32)\n",
      "16 tf.Tensor(202.59567, shape=(), dtype=float32)\n",
      "17 tf.Tensor(202.51657, shape=(), dtype=float32)\n",
      "18 tf.Tensor(202.4552, shape=(), dtype=float32)\n",
      "19 tf.Tensor(202.40773, shape=(), dtype=float32)\n",
      "20 tf.Tensor(202.3711, shape=(), dtype=float32)\n",
      "21 tf.Tensor(202.34259, shape=(), dtype=float32)\n",
      "22 tf.Tensor(202.3205, shape=(), dtype=float32)\n",
      "23 tf.Tensor(202.30345, shape=(), dtype=float32)\n",
      "24 tf.Tensor(202.29025, shape=(), dtype=float32)\n",
      "25 tf.Tensor(202.28004, shape=(), dtype=float32)\n",
      "26 tf.Tensor(202.27219, shape=(), dtype=float32)\n",
      "27 tf.Tensor(202.26593, shape=(), dtype=float32)\n",
      "28 tf.Tensor(202.2612, shape=(), dtype=float32)\n",
      "29 tf.Tensor(202.2575, shape=(), dtype=float32)\n",
      "30 tf.Tensor(202.25468, shape=(), dtype=float32)\n",
      "31 tf.Tensor(202.2525, shape=(), dtype=float32)\n",
      "32 tf.Tensor(202.25078, shape=(), dtype=float32)\n",
      "33 tf.Tensor(202.2495, shape=(), dtype=float32)\n",
      "34 tf.Tensor(202.2484, shape=(), dtype=float32)\n",
      "35 tf.Tensor(202.24765, shape=(), dtype=float32)\n",
      "36 tf.Tensor(202.247, shape=(), dtype=float32)\n",
      "37 tf.Tensor(202.2466, shape=(), dtype=float32)\n",
      "38 tf.Tensor(202.24617, shape=(), dtype=float32)\n",
      "39 tf.Tensor(202.24588, shape=(), dtype=float32)\n",
      "40 tf.Tensor(202.2457, shape=(), dtype=float32)\n",
      "41 tf.Tensor(202.24557, shape=(), dtype=float32)\n",
      "42 tf.Tensor(202.24532, shape=(), dtype=float32)\n",
      "43 tf.Tensor(202.24521, shape=(), dtype=float32)\n",
      "44 tf.Tensor(202.24518, shape=(), dtype=float32)\n",
      "45 tf.Tensor(202.2451, shape=(), dtype=float32)\n",
      "46 tf.Tensor(202.24509, shape=(), dtype=float32)\n",
      "47 tf.Tensor(202.245, shape=(), dtype=float32)\n",
      "48 tf.Tensor(202.245, shape=(), dtype=float32)\n",
      "49 tf.Tensor(202.24498, shape=(), dtype=float32)\n",
      "50 tf.Tensor(202.24501, shape=(), dtype=float32)\n",
      "51 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "52 tf.Tensor(202.24492, shape=(), dtype=float32)\n",
      "53 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "54 tf.Tensor(202.24498, shape=(), dtype=float32)\n",
      "55 tf.Tensor(202.24498, shape=(), dtype=float32)\n",
      "56 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "57 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "58 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "59 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "60 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "61 tf.Tensor(202.24487, shape=(), dtype=float32)\n",
      "62 tf.Tensor(202.2448, shape=(), dtype=float32)\n",
      "63 tf.Tensor(202.2448, shape=(), dtype=float32)\n",
      "64 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "65 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "66 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "67 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "68 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "69 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "70 tf.Tensor(202.24492, shape=(), dtype=float32)\n",
      "71 tf.Tensor(202.24495, shape=(), dtype=float32)\n",
      "72 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "73 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "74 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "75 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "76 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "77 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "78 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "79 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "80 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "81 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "82 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "83 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "84 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "85 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "86 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "87 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "88 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "89 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "90 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "91 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "92 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "93 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "94 tf.Tensor(202.2449, shape=(), dtype=float32)\n",
      "95 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "96 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "97 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "98 tf.Tensor(202.24489, shape=(), dtype=float32)\n",
      "99 tf.Tensor(202.2449, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_pred=predict_model(X_train,W,b)\n",
    "    loss=loss_func(y_train,y_pred)\n",
    "    W,b,l =train(X_train, y_train, W, b)\n",
    "    \n",
    "    print(epoch,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(1)])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhDtOv5UOB7x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1)])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERq9GOKKciho"
   },
   "source": [
    "### Model Prediction on 1st Examples in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKGvUWahcihp"
   },
   "outputs": [],
   "source": [
    "y_test_pred=predict_model(X_test[0],W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17310, shape=(1,), dtype=float32, numpy=array([5.202331], dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6424"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "## Classification using tf.Keras\n",
    "\n",
    "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow if not done already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0g6lorycihf"
   },
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xFvb5sRcihg"
   },
   "outputs": [],
   "source": [
    "data_Iris = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAB--Qdwcihm"
   },
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJr5dYnocihm",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Iris=pd.get_dummies(data_Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species_Iris-setosa</th>\n",
       "      <th>Species_Iris-versicolor</th>\n",
       "      <th>Species_Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0   1            5.1           3.5            1.4           0.2   \n",
       "1   2            4.9           3.0            1.4           0.2   \n",
       "2   3            4.7           3.2            1.3           0.2   \n",
       "3   4            4.6           3.1            1.5           0.2   \n",
       "4   5            5.0           3.6            1.4           0.2   \n",
       "\n",
       "   Species_Iris-setosa  Species_Iris-versicolor  Species_Iris-virginica  \n",
       "0                    1                        0                       0  \n",
       "1                    1                        0                       0  \n",
       "2                    1                        0                       0  \n",
       "3                    1                        0                       0  \n",
       "4                    1                        0                       0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D95nY5ILcihj"
   },
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_Iris.iloc[:,1:5].values\n",
    "Y = data_Iris.iloc[:,5:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERq9GOKKciho"
   },
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKGvUWahcihp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b22qpC5xcihr"
   },
   "source": [
    "###  Building Model in tf.keras\n",
    "\n",
    "Build a Linear Classifier model  <br>\n",
    "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
    "2. Apply Softmax on Dense Layer outputs <br>\n",
    "3. Use SGD as Optimizer\n",
    "4. Use categorical_crossentropy as loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Initialize Sequential Graph (model)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize input data\n",
    "#Input Layer\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))\n",
    "\n",
    "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
    "\n",
    "#Hidden layers\n",
    "model.add(tf.keras.layers.Dense(4,activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(4,activation='tanh'))\n",
    "\n",
    "#outputlayer\n",
    "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "\n",
    "#Compile the model - add Loss and Gradient Descent optimizer\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy') # we can use mae also (Mean absolute error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5FdzqIKcihw"
   },
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 8ms/sample - loss: 0.9042 - val_loss: 1.0416\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.8924 - val_loss: 1.0346\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.8776 - val_loss: 1.0285\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.8745 - val_loss: 1.0217\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.8639 - val_loss: 1.0147\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.8476 - val_loss: 1.0079\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.8477 - val_loss: 1.0012\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.8255 - val_loss: 0.9949\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.8233 - val_loss: 0.9881\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.8130 - val_loss: 0.9827\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.8018 - val_loss: 0.9763\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.7891 - val_loss: 0.9699\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.7915 - val_loss: 0.9630\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7745 - val_loss: 0.9556\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7604 - val_loss: 0.9475\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7642 - val_loss: 0.9405\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7629 - val_loss: 0.9322\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7496 - val_loss: 0.9227\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7239 - val_loss: 0.9131\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7350 - val_loss: 0.9024\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7111 - val_loss: 0.8914\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7115 - val_loss: 0.8807\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.7086 - val_loss: 0.8684\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.6936 - val_loss: 0.8550\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.6831 - val_loss: 0.8410\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.6790 - val_loss: 0.8281\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.6689 - val_loss: 0.8142\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.6604 - val_loss: 0.7996\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.6621 - val_loss: 0.7859\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.6521 - val_loss: 0.7725\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.6397 - val_loss: 0.7587\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.6435 - val_loss: 0.7449\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.6282 - val_loss: 0.7315\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.6552 - val_loss: 0.7186\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.6281 - val_loss: 0.7050\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.6128 - val_loss: 0.6955\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.6189 - val_loss: 0.6833\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.6239 - val_loss: 0.6725\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.5893 - val_loss: 0.6630\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5793 - val_loss: 0.6535\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.6036 - val_loss: 0.6443\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.5888 - val_loss: 0.6349\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.6150 - val_loss: 0.6296\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.5607 - val_loss: 0.6232\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.5747 - val_loss: 0.6137\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.5541 - val_loss: 0.6063\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.5601 - val_loss: 0.5980\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.5497 - val_loss: 0.5922\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.5495 - val_loss: 0.5841\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.5588 - val_loss: 0.5769\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.5411 - val_loss: 0.5687\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.5304 - val_loss: 0.5641\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.5540 - val_loss: 0.5607\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 59us/sample - loss: 0.5193 - val_loss: 0.5555\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.5186 - val_loss: 0.5491\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.5222 - val_loss: 0.5444\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.5312 - val_loss: 0.5387\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.5023 - val_loss: 0.5305\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.5136 - val_loss: 0.5252\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.5156 - val_loss: 0.5194\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.5163 - val_loss: 0.5152\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.5054 - val_loss: 0.5107\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.4833 - val_loss: 0.5061\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.5020 - val_loss: 0.4998\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.4983 - val_loss: 0.4927\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.5066 - val_loss: 0.4902\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.4654 - val_loss: 0.4853\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.4736 - val_loss: 0.4795\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.4431 - val_loss: 0.4759\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.4596 - val_loss: 0.4696\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.4694 - val_loss: 0.4660\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.4895 - val_loss: 0.4644\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 45us/sample - loss: 0.4635 - val_loss: 0.4601\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.4468 - val_loss: 0.4549\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.4463 - val_loss: 0.4518\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.4437 - val_loss: 0.4484\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.4474 - val_loss: 0.4458\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 93us/sample - loss: 0.4407 - val_loss: 0.4404\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.4443 - val_loss: 0.4342\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.4378 - val_loss: 0.4299\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.4241 - val_loss: 0.4262\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 53us/sample - loss: 0.4584 - val_loss: 0.4226\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.4288 - val_loss: 0.4192\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.4150 - val_loss: 0.4156\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.4416 - val_loss: 0.4098\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.4158 - val_loss: 0.4068\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.4348 - val_loss: 0.4040\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.4051 - val_loss: 0.4006\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.4077 - val_loss: 0.3971\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.4467 - val_loss: 0.3952\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.4390 - val_loss: 0.3938\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.3956 - val_loss: 0.3910\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.4008 - val_loss: 0.3881\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.4205 - val_loss: 0.3860\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.3915 - val_loss: 0.3843\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.4001 - val_loss: 0.3810\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.4068 - val_loss: 0.3769\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.4041 - val_loss: 0.3750\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.3748 - val_loss: 0.3731\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.3830 - val_loss: 0.3703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25830a68be0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-SgSSdRcih5"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06757179, 0.69205844, 0.2403697 ],\n",
       "       [0.8077095 , 0.16089395, 0.03139647],\n",
       "       [0.03253098, 0.18811189, 0.77935714],\n",
       "       [0.06708154, 0.44726694, 0.48565152],\n",
       "       [0.06002674, 0.68524146, 0.25473186],\n",
       "       [0.7988484 , 0.17037125, 0.03078038],\n",
       "       [0.13639174, 0.6332974 , 0.2303109 ],\n",
       "       [0.03420854, 0.16264848, 0.80314296],\n",
       "       [0.05457136, 0.7769833 , 0.16844533],\n",
       "       [0.07711798, 0.75691754, 0.16596448],\n",
       "       [0.03824357, 0.17108506, 0.79067135],\n",
       "       [0.7992838 , 0.1724534 , 0.02826289],\n",
       "       [0.80550385, 0.16551974, 0.02897646],\n",
       "       [0.8009627 , 0.17080995, 0.02822729],\n",
       "       [0.81873673, 0.15135206, 0.02991119],\n",
       "       [0.06814331, 0.23713121, 0.6947254 ],\n",
       "       [0.03127911, 0.15625574, 0.81246513],\n",
       "       [0.0711083 , 0.7912048 , 0.13768692],\n",
       "       [0.07834115, 0.59953356, 0.32212523],\n",
       "       [0.03217573, 0.16831236, 0.79951185],\n",
       "       [0.804382  , 0.16745713, 0.02816084],\n",
       "       [0.04355762, 0.21404305, 0.7423993 ],\n",
       "       [0.80680764, 0.16366707, 0.02952532],\n",
       "       [0.03322039, 0.17760608, 0.78917354],\n",
       "       [0.04380161, 0.18261239, 0.773586  ],\n",
       "       [0.03315054, 0.16258125, 0.80426824],\n",
       "       [0.04907218, 0.4068348 , 0.544093  ],\n",
       "       [0.03103579, 0.1504391 , 0.81852514],\n",
       "       [0.7947559 , 0.17604725, 0.02919683],\n",
       "       [0.7991234 , 0.17222452, 0.02865206],\n",
       "       [0.8174632 , 0.15520875, 0.02732806],\n",
       "       [0.83257174, 0.12304405, 0.04438426],\n",
       "       [0.07509347, 0.5650406 , 0.3598659 ],\n",
       "       [0.8099215 , 0.16203363, 0.02804497],\n",
       "       [0.8093849 , 0.16324411, 0.02737098],\n",
       "       [0.05042452, 0.40541443, 0.544161  ],\n",
       "       [0.075417  , 0.35072663, 0.57385635],\n",
       "       [0.80895513, 0.16269872, 0.02834615],\n",
       "       [0.81396425, 0.15807548, 0.02796031],\n",
       "       [0.8232492 , 0.14662585, 0.0301249 ],\n",
       "       [0.03991478, 0.22162394, 0.7384613 ],\n",
       "       [0.10663618, 0.19821243, 0.6951514 ],\n",
       "       [0.06457121, 0.43900368, 0.49642503],\n",
       "       [0.8178836 , 0.15106146, 0.03105491],\n",
       "       [0.8114238 , 0.159798  , 0.02877825]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBgKZkhkcih6"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_val=y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(metrics.accuracy_score(y_test_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P32ASP1Vjt0a"
   },
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8rd0jjAjyTR"
   },
   "outputs": [],
   "source": [
    "model.save('R6Lab_TF_&_Keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XiipRpe7rbVh"
   },
   "source": [
    "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
    "\n",
    "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5Du3lubr4sA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3. R6_InternalLab_AIML_Share_Prices-Eager Execution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
